\chapter{Preliminaries}
\label{prelims}

In this chapter we will introduce the type theoretic background
material for the thesis. We will not give a detailed overview of
Martin-L\"of Type Theory in this chapter. For such an overview, we
refer the reader to the first chapter of \cite{UFP2013}. Instead, we
introduce notation and basic propositions and lemmata that we will use
throughout the thesis. As we will be using category theoretic
approaches, the chapter is concluded with our approach to category
theory in type theory.

\section{Basic type formers}
In type theory we can form $\Pi$-types, or dependent functions, given
a type $A$ and for every $a : A$ a type $B\ a$, we have the type:
$$
(x : A) \to B\ a
$$
Traditionally this is denoted as $\Pi (x : A) . B\ a$ or $\Pi A . B$.
We will use Agda's notation for $\Pi$-types instead, along with its
convention of leaving out arrows in the case of nested $\Pi$-types,
where convenient, \eg we may write
$(a : A) \to (b : B\ a) \to C\ a\ b$ as
$(a : A)\ (b : B\ a) \to C\ a\ b$. The introduction rule for
$\Pi$-types is that if we have $x : A$ in our context and a term
$b : B\ x$, then we can form the term:
$$
\lambda x . b : (x : A) \to B\ x
$$
$\Pi$-types have an elimination rule, called \emph{application}: if
$f : (x : A) \to B\ x$ and $x : A$, then $f\ x : B\ x$. Terms of
$\Pi$-types are subject to two classes of definitional equalities,
$\beta$-equality:
$$
(\lambda x . e)\ y \defeq e[x/y]
$$
where $e[x/y]$ denotes the substitution of every occurrence in $e$ of
$x$ with $y$. We use the symbol $\defeq$ to denote definitional
equality on terms.

Furthermore we have $\eta$-equality, for every $f : (x : A) \to B\ x$:
$$
f \defeq \lambda x . f\ x
$$
Note that if the codomain of a $\Pi$-type does not refer to elements
of its domain, \ie when we have a non-dependent function, we denote it
as $A \to B$.

Apart from $\Pi$-types, we also have $\Sigma$-types, or dependent
pairs/products. The type formation rule is similar to that of
$\Pi$-types: if we have a type $A$ such that if we have $a : A$ in our
context, the term $B\ a$ is a type, then we have that the following is a type:
$$
(x : A) \times B\ a
$$
This is traditionally written as $\Sigma (x : A) . B\ a$ or
$\Sigma A . B$, but we are using a notation here which mirrors Agda's
notation for $\Pi$-types.

The type $(x : A) \times B\ x$ comes with two projection functions:
\begin{itemize}
\item $\pi_0 : (x : A) \times B\ x \to A$
\item $\pi_1 : (a : (x : A) \times B\ x) \to B\ (\pi_1\ a)$
\end{itemize}
Since we are explicitly giving a name to the first element of the
pair, we can also use the following notation, where we let the scope
of $x$ range over the whole expression after its introduction:
$$
\pi_1 : (x : A) \times B\ x \to B\ x
$$
The $\eta$-law for $\Sigma$-types gives us the following definitional
equality for every pair $z : \Sigma A B$:
$$
z \defeq (\pi_0\ z , \pi_1\ z)
$$

\subsection{Universes}

Another basic type is the type whose inhabitants themselves are again
types, the universe $\Type$. Using such a universe, we can now
rephrase the type formation for $\Pi$-types as having a term:
$$
\Pi : (A : \Type) \to (B : A \to \Type) \to \Type
$$
Such a universe may not have the property that $\Type : \Type$ as that
gives rise to a paradox, similar to Russell's paradox in set
theory. Instead, we have a hierarchy of universes:
$$
\Type_0 : \Type_1 : \Type_2 : \hdots
$$
While avoiding the paradox, this hierarchy brings a lot of complexity
to our language in terms of usability. Every time we use a universe,
we have to explicitly indicate its level, cluttering our terms.

One solution to this problem is to leave the level indices as implicit
variables with constraints. One can then let the type checker attempt
to solve this system, which is the approach Coq takes. 

Another problem is that we may want to give definitions that can be
instantiated to more than one level. If we want to define a function
composition operator, we would like that it works for functions
between types of any level. In Agda, we have the notion of
\emph{universe polymorphism}. We can define terms such as:
\begin{align*}
  &\id : (n : \Level)\ (A : \Type_n) \to A \to A \\
  &\id\ n\ A\ x \ddefeq x
\end{align*}
The function $\id$ is polymorphic over all levels $n$. While this
saves us from having to define $\id$ for any level, universe
polymorphism does introduce some complexity of its own. $\Level$ is
\emph{not} a type, which means that while
$(n : \Level)\ (A : \Type_n) \to A \to A$ is a valid Agda
\emph{expression}, it is not a type, \ie it is not an inhabitant of
$\Type_i$ for any $i : \Level$.

In this thesis we will leave the universe levels implicit.

\subsection{Implicit arguments}

An important feature of Agda is that we can denote arguments of a
function as being an \emph{implicit argument}. One use case is the
aforementioned universe levels. If we consider again the type and
definition of $\id$, with implicit arguments, we can write:
\begin{align*}
&\id : \{\ n : \Level\ \}\ \{\ A : \Type_n\ \} \to A \to A \\
&\id\ x \ddefeq x
\end{align*}
The idea here is that the context in which a function is called gives
information we can use to fill in the blanks: if we call $\id$ with a
certain argument, we know the type of the argument and in turn also
know the universe level of that type. To improve readability we will
oftentimes implicitly pass around parameters, while sometimes making
them explicit by adding subscripts.

\subsection{Inductive data types}

As mentioned in the introduction, an important feature to have in a
type theory is to have a way to define custom inductive data types. In
Agda, one can define an inductive type by giving a list of
constructors. For example, the natural numbers can be defined as
follows:
\begin{datatype}{\natty}{\Type}
  \constr{\natzero}{\natty} \\
  \constr{\natsucc}{\natty \to \natty}
\end{datatype}
We will often use Agda-like notation to give
definitions/specifications of inductive types.

Two trivial, yet important types we will use are the empty and the
unit types, which can be defined as inductive types:
\begin{datatype}{\emptyty}{\Type}
\end{datatype}
%
\begin{datatype}{\unitty}{\Type}
  \constr{\unitval}{\unitty}
\end{datatype}
%
The ``smallest non-trivial'' data type, $\boolty$ can also be defined
inductively:
\begin{datatype}{\boolty}{\Type}
  \constr{\boolt}{\boolty} \\
  \constr{\boolf}{\boolty}
\end{datatype}

Inductive definitions may also be parametrised. We may define the
coproduct of two types as follows:
\begin{datatype}{\sumty{\_}{\_}\ (A\ B : \Set)}{\Set}
  \constr{\suminl}{A \to \sumty{A}{B}} \\
  \constr{\suminr}{B \to \sumty{A}{B}}
\end{datatype}

Inductive data type declarations in Agda do not give us elimination
principles directly. Instead Agda has a notion of \emph{dependent
  pattern matching} \cite{Coquand1992}: we write our functions out of
inductive types by matching against the possible constructors of said
types. These function definitions may be recursive, as long as the
recursive occurrences are on a subterm of the pattern. Dependent
pattern matching has been shown to be equivalent to having
eliminators, assuming all types satisfy uniqueness of identity proofs
\cite{Goguen2006}. However, with some further restrictions on pattern
matching, translations to eliminators without requiring uniqueness of
identity proofs do exist \cite{Cockx2014}. Moreover, the translation
of pattern matching definitions into definitions with eliminators does
not always preserve definitional equalities \cite{McBride2006ii}.

As opposed to adding inductive types to the theory in an ad hoc
manner, one can add W-types as a primitive and define all inductive
types in terms of this primitive. W-types are enough to give us
ordinary inductive types as well as indexed inductive types.

In this thesis, the inductive definitions we need to formalise the
theory of quotient inductive-inductive types, can all be written using
W-types. However, for sake of convenience and presentational clarity,
we will use Agda its notation to present these. We will also sometimes
give function definitions by pattern matching, but these can be
trivially rewritten using just the eliminators.

\section{Equality}

So far we have mentioned definitional equality between terms. This
equality is a metatheoretic notion, it is external to the type theory,
\ie $x \defeq y$ is not a type nor a term. We can define a notion of
equality between terms in the type theory itself, referred to as
\emph{propositional equality}:

\begin{definition}[Identity types]
  Given a type $A : \Type$ and $x, y : A$, we define the type
  $x = y : \Type$, inductively with constructor:
  $$
  \refl : (x : A) \to x = x
  $$
  A type $x = y$ is called an \emph{identity type}.
  
  The elimination principle for identity types is:
  \begin{align*}
  \J : &\ (A : \Type)\ (P : (x\ y : A) \to x = y \to \Type)\ \\
  &\ (m : (x : A) \to P\ x\ x\ (\refl\ x)) \\
  &\ \to (x\ y : A)\ (p : x = y) \to P\ x\ y\ p
  \end{align*}
  which satisfies the computation rule:
  $$
  \J\ A\ P\ m\ x\ x\ (\refl\ x) \defeq m\ x
  $$
\end{definition}

\begin{remark}
  While it is called \emph{propositional} equality, the type $x = y$
  need not be propositional in general.
\end{remark}

\begin{lemma}
  Given a type $A : \Type$, the identity types form an equivalence
  relation on $A$.
\end{lemma}

\begin{proof}
  We need to show that the relation $\_ = \_ : A \to A \to \Type$ is
  reflexive, symmetric and transitive. Reflexivity we immediately get
  from the $\refl$ constructor. For symmetry we need to appeal to the
  elimination principle. Let $p : x = y$, we define $\sym{p} : y = x$:
  $$
  \sym{p} \ddefeq \J\ A\ (\lambda x\ y\ p . y = x)\ (\lambda x . \refl\ x)\ x\ y\ p
  $$
  For transitivity, we need an operation:
  $$
  \trans{\_}{\_} : x = y \to y = z \to x = z
  $$
  This can be defined by path induction on any of combination of its
  arguments.
\end{proof}

\begin{lemma}
  The identity types on a type $A : \Type$ form a groupoid with
  respect to propositional equality.
\end{lemma}

\begin{proof}
  The identity types on $A$ form a groupoid with transitivity as its
  composition, its inverses given by symmetry and the unit being
  reflexivity. These operations need to adhere to the following laws:
  \begin{itemize}
  \item associativity: $(p : x = y) (q : y = z) (r : z = w) \to \trans{(\trans{p}{q})}{r} = \trans{p}{(\trans{q}{r})}$
  \item left identity: $(p : x = y) \to \trans{\refl_x}{p} = p$
  \item right identity: $(p : x = y) \to \trans{p}{\refl_y} = p$
  \item left inverse: $(p : x = y) \to \trans{\sym{p}}{p} = \refl_y$
  \item right inverse: $(p : x = y) \to \trans{p}{\sym{p}} = \refl_x$
  \end{itemize}
  These can all be shown to hold by straightforward path induction.
\end{proof}

\begin{remark}
  The computational properties of transitivity obviously depend on how
  it is defined: we either get the left identity or the right identity
  law to hold definitionally if we perform path induction on one
  argument. If it is defined by path induction on both arguments, we
  get neither law ``for free''. We can make a new definition of
  propositional equality on top of the original one, which satisfies
  the category laws definitionally, as we will see in
  \cref{alt-identity-type}.
\end{remark}

Since identity types are types again, they themselves are also
equipped with a groupoid structure. We can always consider identity
types of identity types of identity types, et cetera. Such an infinite
tower of groupoids on top of each other is called an \inftygrpd. An
external proof of the fact that every type gives rise to an \inftygrpd
has been given \cite{VanDenBerg2011,Lumsdaine2009}.

\subsection{Dependent equality}

When considering type families $B : A \to \Type$ over some type $A$, we
sometimes find ourselves in the situation that we want to talk about
equality of $a : B\ x$ and $b : B\ y$ where $x = y$ but not
necessarily $x \defeq y$. In this case the term $a = b$ is
well-typed. However, given a path $x = y$, inhabitants of $B\ x$ can
be \emph{transported} to inhabitants of $B\ y$:
\begin{definition}
  Given $A : \Type$ and $B : A \to \Type$, we define:
  \begin{align*}
    &\transport\ B : (p : x = y) \to B\ x \to B\ y \\
    &\transport\ B\ p\ a \ddefeq J\ A\ (\lambda x\ y\ q . B\ x \to B\ y)\ (\lambda x\ a . a)\ p\ a
  \end{align*}
\end{definition}

Using $\transport$ we can define the notion of \emph{dependent path}:
\begin{definition}
  Given $A : \Type$, $B : A \to \Type$ and a path $p : x = y$ for
  $x, y : A$, the type of dependent equalities between $a : B\ x$ and
  $b : B\ y$ is defined as:
  \begin{align*}
    &\pathover{B}{p}{a}{b} : \Type \\
    &\pathover{B}{p}{a}{b} \ddefeq \transport\ B\ p\ a = b
  \end{align*}
\end{definition}

\subsection{Functoriality of functions}

The equality relation is a congruence: it is preserved by any function.

\begin{proposition}
  Given a function $f : A \to B$ and an equality $x = y$, we have
  $f\ x = f\ y$.
\end{proposition}

\begin{proof}
  We can define the operation $\ap$ (action (of the function) on
  paths) by path induction:
  \begin{align*}
    &\ap : (f : X \to Y) \to x = y \to f\ x = f\ y \\
    &\ap\ f\ p \ddefeq \J\ (\lambda x\ y\ p . f\ x = f\ y)\ (\lambda x . \refl_{f\ x})\ x\ y\ p
  \end{align*}
\end{proof}

We can regard the identity type on a type as a category: we have
identity morphisms given by $\refl$ and composition given by
$\trans{\_}{\_}$, which is associative and satisfies the left and
right unit laws. In this light, any function $A \to B$ can be thought
of as a functor from the identity types on $A$ to the identity types
on $B$:

\begin{proposition}
  For any function $f : X \to Y$, $\ap\ f$ is functorial:
  \begin{itemize}
  \item $\ap\ f\ \refl_x = \refl_{f\ x}$
  \item $\ap\ f\ (\trans{p}{q}) = \trans{\ap\ f\ p}{\ap\ f\ q}$
  \end{itemize}
\end{proposition}

\begin{proof}
  By path induction.
\end{proof}

$\ap$ is also functorial in its first argument:

\begin{proposition}
  For any $p : x = y$, the following holds:
  \begin{itemize}
  \item $\ap\ \id_A\ p = p$
  \item $\ap\ (g \circ f)\ p = \ap\ g\ (\ap\ f\ p)$
  \end{itemize}
\end{proposition}

\begin{proof}
  By path induction.
\end{proof}

Apart from having an action on paths for functions, we can define a
similar operation for dependent functions:

\begin{definition}
  \begin{align*}
    &\apd : (f : (x : A) \to B\ x) \to (p : x = y) \to \pathover{B}{p}{f\ x}{f\ y}
  \end{align*}
  is defined by path induction similar to $\ap$.
\end{definition}

A useful property of dependent paths over families of which the fibres
are equalities is the following:

\begin{proposition}
  Let $f, g : X \to Y$ be two functions, $x, y : X$ and suppose we
  have the following data:
  \begin{itemize}
  \item $p : f\ x = g\ x$
  \item $q : f\ y = g\ y$
  \item $r : x = y$
  \end{itemize}
  then a dependent equality:
  $$
  \pathover{\lambda x . f\ x = g\ x}{r}{p}{q}
  $$
  is equivalent to:
  $$
  p \ct \ap\ g\ r = \ap\ f\ r \ct q
  $$
\end{proposition}

This proposition allows us to rewrite dependent equalities to
non-dependent ones, which are easier to manipulate and reason about.

\begin{remark}
  When we are dealing with equalities between compositions of paths
  such as in the above proposition, then it makes sense to denote this
  as a commutative diagram. The above example translates to the
  following diagram:
  $$
  \xymatrix{
    f\ x 
    \ar@{-}[r]^{p}
    \ar@{-}[d]_{\ap f r}
    &g\ x
    \ar@{-}[d]^{\ap g r}
    \\
    f\ y
    \ar@{-}[r]_{q}
    &g\ y
  }
  $$
  Paths are denoted with lines with no arrow heads, as they are
  invertible. Since direction is not always relevant, we usually
  denote $\sym{p}$ as $p$ in such a diagram.
\end{remark}

\subsection{Truncation levels}

If we consider the tower of identity types for a specific type $A$, it
is sometimes the case that after several levels the identity types
\emph{vanish}, \ie they are equivalent to the unit type. Another way
of stating that a type is equivalent to the unit type is that it is
\emph{contractible}:

\begin{definition}
  A type $A$ is \emph{contractible} if there exists a ``central''
  point $c : A$ such that every point is connected to the centre via
  an equality:
  \begin{align*}
    &\iscontr : (A : \Type) \to \Type \\
    &\iscontr A \ddefeq (c : A) \times ((x : A) \to c = x)
  \end{align*}
\end{definition}

We can show that the identity types for a contractible type are again
contractible: $\iscontr\ A \to (x\ y : A) \to \iscontr\ (x = y)$. The
level at which the identity types vanish is the so called
\emph{truncation level} or \emph{h-level} of the type:
\begin{definition}
  A type has truncation level $n : \natty_{-2}$, if we have a proof of
  $\istrunc{n}\ A$ where $\istrunc{n}$ is defined recursively over $n$:
  \begin{align*}
    &\istrunc{n} : (A : \Type) \to \Type \\
    &\istrunc{-2}\ A \ddefeq \iscontr\ A \\
    &\istrunc{n+1}\ A \ddefeq (x\ y : A) \to \istrunc{n}\ (x = y)
  \end{align*}
\end{definition}

For our purposes, there are two important truncation levels, apart
from contractibility:
\begin{definition}
  A type is a \emph{proposition} or \emph{propositional} if it has
  truncation level $-1$.
\end{definition}

A useful characterisation of propositions is given by the following
proposition:
\begin{proposition}
  If the type $A$ satisfies $(x\ y : A) \to x = y$ then $A$ is
  propositional.
\end{proposition}
From this characterisation, we immediately see that if $A$ is
propositional, then it is either empty or contractible, \ie uniquely
inhabited up to propositional equality. Of course, we do not have an
internal proof of
$(A : \Type) \to \isprop\ A \to (A \to \emptyty) + (\iscontr\ A)$,
which is essentially the law of excluded middle.

The next truncation level, level $0$, are the so called sets:
\begin{definition}
  A type is a \emph{set} if it has truncation level $0$, \ie for all
  $x, y : A$, $x = y$ is propositional.
\end{definition}
The property of being a set is also called ``uniqueness of identity
proofs''.
\begin{definition}
  We define the universe of sets as follows:
  \begin{align*}
    &\Set : \Type \\
    &\Set \ddefeq (X : \Type) \times \isset\ X
  \end{align*}
\end{definition}

For the sake of brevity, we will not be explicit about projecting the
type out inhabitants of $\Set$ and will write things such as
$(A : \Set) \to A \to A$, as though it were $\Type$.

\subsection{Equivalence}

We have a notion of equality on types, so far have not talked in great
detail about equality on a universe of types, \ie equality
\emph{between} types.

A very weak notion of types being equal is ``logical equivalence'':
\begin{definition}
  Types $A$ and $B$ are \emph{logically equivalent} if we have
  functions $A \to B$ and $B \to A$:
  \begin{align*}
    &A \logequiv B : \Type \\
    &A \logequiv B \ddefeq (A \to B) \times (B \to A)
  \end{align*}
\end{definition}

With logical equivalence we do not have any requirements on the two
functions between the two types, just that there exist any. There
being a logical equivalence is also not a proposition: the type
$\boolty \logequiv \boolty$ has two distinct inhabitants:
$(\id_{\boolty} , \id_{\boolty})$ and $(\boolnot , \boolnot)$.

The notion of isomorphism also requires the two functions to be
each other's inverses:
\begin{definition}[Isomorphism]
  Types $A$ and $B$ are \emph{isomorphic} if they are each other's
  inverse:
  \begin{align*}
    &\Iso{A}{B} : \Type \\
    &\Iso{A}{B} \ddefeq (f : A \to B) \times (g : B \to A)  \\
    &\ \ \ \ \ \ \times ((x : A) \to g\ (f\ a) = a) \times ((y : B) \to f\ (g\ y) = y)
  \end{align*}
\end{definition}

The type of isomorphisms is not necessarily propositional: the
examples given for logical equivalence can be shown to be distinct
isomorphisms as well.

One downside of the notion of isomorphism is that given a function
$f : A \to B$, the ``proposition'' whether $f$ is an isomorphism or
not is not propositional, \ie the following type is not in general a
proposition:
$$
(g : B \to A) \times (f \circ g = \id_B) \times (g \circ f = \id_A)
$$
A more well-behaved notion is the notion of equivalence:
\begin{definition}[Equivalence]
  A function $f : A \to B$ is an \emph{equivalence} if the following
  type is inhabited:
  $$
  (g : B \to A) \times f \circ g = \id_B \times (h : B \to A) \times h \circ f = \id_A
  $$
  
  If there exists an equivalence between types $A$ and $B$, we denote
  this as $\Equiv{A}{B}$.
\end{definition}

\begin{proposition}
  Every isomorphism gives rise to an equivalence.
\end{proposition}

\begin{proposition}
  Given a function $f : A \to B$, the property of $f$ being an
  equivalence is a proposition.
\end{proposition}

For a function to be an equivalence is a proposition, but for two
types to be equivalent is not propositional. The same example as for
logical equivalence and isomorphism can be used to show this.

Note that all these relations are equivalence relations. We can also
show that composing them is associative. Isomorphisms and
equivalences furthermore satisfy the groupoid laws.

\subsection{Univalence}

We have seen that we can formulate an appropriate notion of equality
between types, but now we have two different ways of stating equality
on the universe of types: equivalence and identity types. All the
things we prove about identity types, have to proven again for
equivalences. 

While identity types come with the path induction principle,
equivalences do not enjoy such an induction principle. Even though we
lack such a principle, we still can show that equivalences form an
equivalence relation and also satisfy the groupoid laws. Once we try
to show that equivalence gives us a congruence relation, we get
stuck. In other words: we do not have a prove of the statement that
every construction in type theory is invariant under equivalence.

\begin{definition}
  Every equality between types gives rise to an isomorphism:
  \begin{align*}
    &\idtoequiv : (A = B) \to \Equiv{A}{B} \\
    &\idtoequiv \ddefeq \J\ (\lambda A\ B\ p . \Equiv{A}{B}))\ (\lambda A \to \idequiv\ A)
  \end{align*}

  where $\idequiv$ is the identity equivalence $\Equiv{A}{A}$.
\end{definition}

\begin{definition}[Univalence]
  A universe of types is \emph{univalent} if the function $\idtoequiv$
  is an equivalence.
\end{definition}

Hence univalence gives us an equivalence:
$$
(\Equiv{A}{B}) = (A = B)
$$
As equivalence and equality between types are equal things, we will
speak about equivalences between types whilst using the symbol for
equality.

Often we will give an equality between types by providing an
isomorphism, which gives us an equivalence, which gives us an equality
by virtue of univalence.

We will assume univalence holds for our universes of types unless
otherwise indicated.

\subsection{Function extensionality}

In ordinary mathematics, one usually proves that two functions are
equal by showing that they are pointwise equal: we appeal to function
extensionality. In type theory this can be formulated as follows:
\begin{definition}[Function extensionality]
  Suppose we have functions $f, g : (x : X) \to P\ x$, function
  extensionality gives us a term of type:
  $$
  ((x : X) \to f\ x = g\ x) \to f = g
  $$
\end{definition}

Function extensionality is not something that is provable in ordinary
\mltt. However, it does follow from univalence and as we will see, it
also follows from having quotients. In fact, these imply we have \emph{strong function extensionality}:

\begin{proposition}[Strong function extensionality]
  For any two functions $f, g : (x : X) \to P\ x$, we have the following equivalence:
  $$
  ((x : X) \to f\ x = g\ x) = (f = g)
  $$
\end{proposition}

\subsection{Equivalences of $\Sigma$-types}

We often work with nested $\Sigma$-types and have to provide
equivalences between them. There are basic equivalences that we often
use to build up our bigger equivalences of.

For non-dependent products, we can show that it satisfies laws of a
commutative monoid using univalence (these do not hold
definitionally):
\begin{itemize}
\item $A \times \unitty = \unitty \times A = A$
\item $A \times (B \times C) = (A \times B) \times C$
\item $A \times B = B \times A$
\end{itemize}
We have similar properties for $\Sigma$-types:
\begin{itemize}
\item $(a : A) \times \unitty = (x : \unitty) \times A = A$
\item $(a : A) \times ((b : B) \times C\ (a , b)) = (x : (a : A) \times B\ a) \times C\ x$
\end{itemize}
Commutativity only makes sense when the types do not depend on
each other, so we do not have such a statement for $\Sigma$-types. In
equational reasoning we will not be explicit about applying
associativity or other laws and often will neglect parentheses.

\begin{proposition}[Singleton contraction]
  For any type $A : \Type$ and $a : A$, we have the following
  equivalence:
  $$
  ((x : A) \times (x = a)) = \unitty
  $$
\end{proposition}

\begin{proof}
  This follows directly from path induction.
\end{proof}

The type $(x : A) \times (x = a)$ is called a \emph{singleton}. This
fact is very useful in equational reasoning. It is comparable to high
school algebra where multiplying by $\frac{a}{a}$ for a cleverly
chosen expression $a$, or recognising that two factors cancel
each other out, are a useful techniques.

\begin{proposition}[Equality of inhabitants of $\Sigma$-types]
  Equality between inhabitants of a $\Sigma$-type is equivalent to a
  $\Sigma$-type of equalities. Given a family $A : Type$,
  $B : A \to \Type$, and $x , y : A$, $z : B\ a$, $w : B\ y$, we have:
  $$
  ((x , z) = (y , w)) = (p : x = y) \times (q : \pathover{B}{p}{z}{w})
  $$
\end{proposition}

\subsection{Alternative formulation of identity types}
\label{alt-identity-type}
We have seen that the identity types form a groupoid on its underlying
type. The unit and associativity laws do not hold definitionally for
this groupoid. When reasoning about equalities \emph{between} paths,
it can be annoying if we have to take associativity into account. For
example, suppose we want to prove
$a \ct p \ct (\sym{p} \ct b) = a \ct b$, for some expressions $a$ and
$b$. The easiest way to prove this is by applying path induction to
$p$, which will reduce the goal to $a \ct b = a \ct b$. However,
sometimes we are in comparable situations where we cannot perform path
induction on all of the paths involved.
\begin{align*}
  &a \ct p \ct (\sym{p} \ct b) \\
  &= \\
  &a \ct ((p \ct \sym{p}) \ct b) \\
  &= \\
  &a \ct (\refl \ct b) \\
  &= \\
  &a \ct b
\end{align*}

Because associativity does not hold definitionally, we cannot give as
proof term:
$$
\ap\ (\lambda h . a \ct h \ct b) (sym-inv\ p) : a \ct (p \ct \sym{p}) \ct b = a \ct b
$$
as it has the wrong type, hence we are stuck with filling in
associativity and unit laws here and there. This is particularly
frustrating when one then has to prove things about the resulting path
being equal to something else.

We can define an alternative formulation of identity types which have
different computational properties. This formulation is based on the
insight that functions on $\Type$ do satisfy the associativity and
unit laws definitionally with respect to function composition. We define:
$$
x \alteq_{A} y \ddefeq (z : A) \to z = x \to z = y
$$
Reflexivity is then redefined as the identity function and
transitivity is given by function composition. There are functions to
and fro between the two formulations:
\begin{align*}
  &to : x = y \to x \alteq y \\
  &to\ p = \lambda z\ q . \trans{q}{p} \\
  \\
  &from : x \alteq y \to x = y \\
  &from\ p = p\ x\ \refl_{x}
\end{align*}

\begin{proposition}
  Given a type $A : \Type$ with elements $x, y : A$, we have an equivalence:
  $$
  (x \alteq_{A} y) = (x =_{A} y)
  $$
\end{proposition}

\begin{proof}
  The functions $to$ and $from$ give us an isomorphism. Let $p : x = y$, then we have that:
  $$
  from\ (to\ p) = from\ (\lambda z\ q . \trans{q}{p}) = \trans{\refl}{p} = p
  $$
  In the other direction we get for $p : x \alteq y$:
  $$
  to\ (from\ p) = to\ (p\ x\ \refl) = \lambda z\ q . \trans{q}{p\ x\ \refl}
  $$
  Showing that this is equal to $p$ can be done by employing function
  extensionality and applying path induction on the second
  argument. This is essentially showing that $p$ is a natural
  transformation.
\end{proof}

This equivalence also maps reflexivitiy and transitivity of the
original identity types onto composition of the alternative version
and vice versa. The alternative identity types also satisfy the path
induction principle.

The above equivalence is also a direct consequence of the type
theoretic Yoneda lemma \cite{Rijke2012}.

\section{Category theory in type theory}

When defining the concept of category in type theory, we have to make
several choices. A naive way of defining a category would be as the
following $\Sigma$-type:
$$
\Cat \ddefeq (obj : \Type) \times (hom : obj \to obj \to \Type) \times (\hdots)
$$
where on the place of the ellipsis one would have to fill in the
category structure and laws. This definition of category gives rise to
certain problems, which we briefly mention in \cref{higher-cats} and
in more detail in \cref{untruncated}.

We will use the definition of category as in
\cite{Ahrens2015}. (However, what we call ``category'' here is called
``precategory'' in that article.)

\begin{definition}[Category]
  We define the type $\Cat : \Type$ as the following $\Sigma$-type:
  %
  \begin{align*}
    \Cat &\ddefeq &&(obj : \Type) \\
         &\times &&(hom : obj \to obj \to \Type) \\
         &\times &&(\identalt{hom-is-set} : (X\ Y : obj) \to \isset (hom\ X\ Y)) \\
         &\times &&(id : (X : obj) \to hom\ X\ X) \\
         &\times &&(comp : \{\ X\ Y\ Z : obj\ \} \to hom\ Y\ Z \to hom\ X\ Y \to hom\ X\ Z) \\
         &\times &&(\identalt{left-id} : \{\ X\ Y : obj\ \}\ (f : hom\ X\ Y) \to comp\ (id\ Y)\ f = f) \\
         &\times &&(\identalt{right-id} : \{\ X\ Y : obj\ \}\ (f : hom\ X\ Y) \to comp\ f\ (id\ X) = f) \\
         &\times &&(assoc : \{\ X\ Y\ Z\ W : obj\ \}\ (h : hom\ Z\ W) (g : hom\ Y\ Z) (f : hom\ X\ Y) \\
         & &&\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \to comp\ (comp\ h\ g)\ f = comp\ h\ (comp\ g\ f))
  \end{align*}
\end{definition}

The type of objects of a category $\Cc$ is denoted with $| \Cc |$. The
type of morphisms given objects $X, Y : | \Cc |$ is denoted as
$\Cc(X,Y)$.

\begin{example}
  The universe $\Set$ of types that are sets forms a category with its
  morphisms defined as functions between sets.
\end{example}

\begin{remark}
  The universe $\Type$ is \emph{not} a category in this sense, as for
  arbitrary types $X, Y$, the function space $X \to Y$ will in general
  not be a set.
\end{remark}

\begin{definition}[Functor]
  Suppose $\Cc, \Dd : \Cat$, then we define the type of functors $\Cc$
  to $\Dd$ as the following $\Sigma$-type:
  %
  \begin{align*}
    \Func{\Cc}{\Dd} &\ddefeq &&(obj : | \Cc | \to | \Dd |) \\
    &\times &&(hom : \{\ X\ Y : | \Cc |\ \} \to \Cc(X,Y) \to \Cc(obj\ X, obj\ Y)) \\
    &\times &&(id : \{\ X : | \Cc |\ \} \to hom\ (\id_{\Cc}\ X) = \id_{\Dd}\ (obj\ X)) \\
    &\times &&(comp : \{\ X\ Y\ Z : | \Cc |\ \}\ (g : \Cc(Y,Z))\ (h : \Cc(X,Y)) \\
    &&&\ \ \to hom\ (g \circ_{\Cc} f) = hom\ g \circ_{\Dd} hom\ f)
  \end{align*}
\end{definition}

As is usual, we will use the notation $F X$, where
$F : \Func{\Cc}{\Dd}$ and $X : | \Cc |$ for the action of $F$ on
object $X$ and $F f$ for the action on morphisms $f : \Cc(X,Y)$. When
defining functors, we will often only define the action on objects and
leave the rest implicit.

\begin{definition}
  The \emph{empty category} $\initcat$ is defined as the category with
  no objects. The \emph{unit category} $\termcat$ is defined as the
  category with one object and no non-trivial automorphisms.
\end{definition}

The categories $\initcat$ and $\termcat$ are respectively initial and
terminal in the category of categories.

As the objects are given by a type, propositional equality gives us a
way to talk about equality between objects. When doing category
theory, we should always work with isomorphism if we want to talk
about objects being equal:

\begin{definition}[Isomorphism]
  Let $X, Y : | \Cc |$ for some $\Cc : \Cat$, then the type of
  isomorphisms between $X$ and $Y$ is defined as:
  \begin{align*}
    \Iso{X}{Y} &\ddefeq &&(to : X \to Y) \\
               &\times &&(from : Y \to X) \\
               &\times &&(\identalt{from-to} : from \circ to = \id_{\Cc}\ X) \\
               &\times &&(\identalt{to-from} : to \circ to = \id_{\Cc}\ Y)
  \end{align*}
\end{definition}

The univalence axiom gives us that for sets the notions of isomorphism
and propositional equality coincide. We can state this property for
any category:

\begin{definition}[Univalent category]
  A category $\Cc$ is called \emph{univalent} if for any two objects
  $X, Y : | \Cc |$ we have the following equivalence:
  $$
  \Iso{X}{Y} = (X = Y)
  $$  
\end{definition}

\begin{proposition}
  The category $\Set$ is univalent.
\end{proposition}

\begin{proof}
  This follows directly from univalence for the universe $\Type$.
\end{proof}

\subsection{Families}

We can define a type of families:
\begin{align*}
  &\Fam : \Type \\
  &\Fam \ddefeq (X : \Type) \times (P : X \to \Type)
\end{align*}
The first projection of $\Fam$ is referred to as the \emph{carrier} or
\emph{underlying type} of the family.

A morphism between two families is a function between the underlying
types and a witness of the fact that this function ``preserves the
predicate'':
\begin{align*}
  &\Fam((X,P),(Y,Q)) \ddefeq (f : X \to Y) \times (g : (x : X) \to P\ x \to Q\ (f\ x))
\end{align*}

\subsection{Higher categories}
\label{higher-cats}

As mentioned before, the universe of types $\Type$ does not form a
category if we take functions as morphisms. Function spaces will in
general not be sets. However, we can define composition and identity
morphisms in the usual way. These will satisfy the category laws
definitionally as well.

We can relax the definition of category to not have hom-\emph{sets}
but hom-\emph{types}. Composition and identity morphisms still make
sense with this generalisation. We may run into issues with the
category \emph{laws}: in some situations it is not enough to simply
have the laws, they also need to be coherent in some sense: the
interaction of the laws with each other needs to satisfy certain laws
as well. Naturally, how these coherence laws interact also has to
adhere to additional higher coherence laws, ad infinitum. In
\cref{untruncated} we will describe the problems and possible
solutions in greater detail.
